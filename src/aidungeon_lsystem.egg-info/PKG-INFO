Metadata-Version: 2.4
Name: aidungeon-lsystem
Version: 0.1.0
Summary: Procedural storytelling prototype using L-systems for layout and Ollama for narration.
Requires-Python: >=3.10
Description-Content-Type: text/markdown
Requires-Dist: requests>=2.31.0
Requires-Dist: fastapi>=0.110.0
Requires-Dist: uvicorn>=0.23.0

# AI Dungeon-Style Prototype

This project sketches a lightweight, offline-friendly workflow for generating dungeon layouts with an L-system grammar and narrating each location with an [Ollama](https://ollama.ai) model.

## Features
- Expandable L-system grammar for branching dungeon graphs.
- Configurable mapping from grammar symbols to gameplay concepts.
- Prompt-driven narrative generation powered by an Ollama-compatible endpoint (local or remote).
- Simple CLI to inspect the generated dungeon as JSON or a quick ASCII overview.

## Quick Start
1. Install Python 3.10+ (and `pip install tomli` if you are on 3.10).
2. Create and activate a virtual environment, then install the package in editable mode:
   ```bash
   pip install -e .
   ```
3. Adjust the configuration at `config/default_config.toml` or provide your own TOML file. The default points to a hosted Ollama-compatible endpoint at `https://341f48ced197.ngrok-free.app/v1/completions`, targeting the faster `deepseek-r1:1.5b` model with a 120â€¯s request timeout; swap in your own URL/model or tweak `timeout` if needed. The L-system grammar itself lives in `config/grammars/classic.toml` and is referenced by name in the config, so you can swap grammars without touching code. Each unique symbol prompts the narrator once (responses are cached after stripping any `<think>...</think>` metadata), so performance scales with the variety of room types rather than total rooms.
4. Generate a dungeon and descriptions:
   ```bash
   aidungeon --config config/default_config.toml
   ```

If Ollama is unavailable, the CLI falls back to placeholder text so you can still iterate on the grammar design.

## Web Explorer
- Launch the interactive web UI:
  ```bash
  aidungeon-web --config config/default_config.toml --host 127.0.0.1 --port 8000
  ```
- Open `http://127.0.0.1:8000` to explore the dungeon. Click room cards to move between connections or regenerate an entirely new layout using the button in the header.

## Configuration
The configuration file governs both the grammar expansion and the narrative prompts. See `config/default_config.toml` for a documented example.

## Development
- Run the CLI with `python -m aidungeon.main --config config/default_config.toml`.
- Extend `aidungeon/lsystem.py` for richer grammars or translation to tilemaps.
- Update `aidungeon/narrative.py` to tweak prompt templates or integrate additional metadata.

## License
MIT
