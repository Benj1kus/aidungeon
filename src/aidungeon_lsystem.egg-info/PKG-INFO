Metadata-Version: 2.4
Name: aidungeon-lsystem
Version: 0.1.0
Summary: Procedural storytelling prototype using L-systems for layout and Ollama for narration.
Requires-Python: >=3.10
Description-Content-Type: text/markdown
Requires-Dist: requests>=2.31.0
Requires-Dist: fastapi>=0.110.0
Requires-Dist: uvicorn>=0.23.0

# AI Dungeon-Style Prototype

This project sketches a lightweight, offline-friendly workflow for generating dungeon layouts with an L-system grammar and narrating each location with an [Ollama](https://ollama.ai) model.

## Features
- Expandable L-system grammar for branching dungeon graphs.
- Configurable mapping from grammar symbols to gameplay concepts.
- Prompt-driven narrative generation powered by an Ollama-compatible endpoint (local or remote).
- Per-room grammars for loot and monsters, each described on demand by the same narrator pipeline, using weighted stochastic rules for extra variety.
- Simple CLI to inspect the generated dungeon as JSON or a quick ASCII overview.

## Quick Start
1. Install Python 3.10+ (and `pip install tomli` if you are on 3.10).
2. Create and activate a virtual environment, then install the package in editable mode:
   ```bash
   pip install -e .
   ```
3. Adjust the configuration at `config/default_config.toml` or provide your own TOML file. The default points to a hosted Ollama-compatible endpoint at `https://341f48ced197.ngrok-free.app/v1/completions`, targeting the faster `deepseek-r1:1.5b` model with a 120â€¯s request timeout; swap in your own URL/model or tweak `timeout` if needed. The L-system grammar itself lives in `config/grammars/classic.toml` and is referenced by name in the config, while narrator prompts and fallbacks live in `config/prompts/default_prompts.toml`. Each unique symbol prompts the narrator once (responses are cached after stripping any `<think>...</think>` metadata), so performance scales with the variety of room types rather than total rooms.
4. Generate a dungeon and descriptions:
   ```bash
   aidungeon --config config/default_config.toml --candidates 10
   ```

If Ollama is unavailable, the CLI falls back to placeholder text so you can still iterate on the grammar design.

## Web Explorer
- Launch the interactive web UI:
  ```bash
  aidungeon-web --config config/default_config.toml --host 127.0.0.1 --port 8000
  ```
- Open `http://127.0.0.1:8000` to explore the dungeon. Click room cards or use `W/A/S/D` to move between connections, and regenerate an entirely new layout using the button in the header.

## Configuration
The configuration file governs both the grammar expansion and the narrative prompts. See `config/default_config.toml` for a documented example.
- Room layout grammars live under `config/grammars`, while per-room loot and monster grammars live under their respective `items/` and `monsters/` subdirectories. Update `config/prompts/default_prompts.toml` to change how rooms, items, and monsters are described.
- Automatic scoring samples multiple dungeons (default 10) and keeps the most "enjoyable" layout based on heuristic weights in `config/default_config.toml` (`[evaluation]` section). Adjust weights for `room_diversity`, `branching_factor`, `loot_presence`, `monster_presence`, `dead_end_penalty`, and `room_count` to bias the selector.
- Grammar files can define weighted rules with TOML arrays of tables. Example:
  ```toml
  [grammar]
  axiom = "F"

  [[grammar.rules.F]]
  value = "F[+K]F[-M]F"
  weight = 3

  [[grammar.rules.F]]
  value = "FF"
  ```

## Development
- Run the CLI with `python -m aidungeon.main --config config/default_config.toml`.
- Extend `aidungeon/lsystem.py` for richer grammars or translation to tilemaps.
- Update `aidungeon/narrative.py` to tweak prompt templates or integrate additional metadata.

## License
MIT
